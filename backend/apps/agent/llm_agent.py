"""
LLM Agent Service - Gemini-powered Intelligent Agent
"""
import os
import json
from typing import Dict, Any, List, Optional
from django.conf import settings
import google.generativeai as genai


class GeminiAgent:
    """
    Intelligent Agent sá»­ dá»¥ng Gemini LLM
    Agent cÃ³ thá»ƒ:
    - Chat vá»›i user
    - PhÃ¢n tÃ­ch há»‡ thá»‘ng
    - Táº¡o content vÃ  image
    - Thá»±c hiá»‡n tasks tá»± Ä‘á»™ng
    """

    def __init__(self):
        # Configure Gemini API
        api_key = getattr(settings, 'GEMINI_API_KEY', None)
        if not api_key:
            api_key = os.environ.get('GEMINI_API_KEY')

        if api_key:
            genai.configure(api_key=api_key)

        # Get model name from settings/env
        model_name = getattr(settings, 'GEMINI_AGENT_MODEL', None)
        if not model_name:
            model_name = os.environ.get('GEMINI_AGENT_MODEL', 'gemini-2.0-flash-exp')

        # System prompt - ReAct Agent with Self-Reasoning
        self.system_prompt = """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
IDENTITY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Báº¡n lÃ  "Agent Dashboard" - AI Assistant quáº£n lÃ½ cÃ¡c tools Ä‘á»ƒ há»— trá»£ user.

KHáº¢ NÄ‚NG Cá»¦A Báº N:
- Táº¡o ná»™i dung bÃ i Ä‘Äƒng (generate_post_content)
- Táº¡o hÃ¬nh áº£nh AI (generate_post_image)
- LÆ°u bÃ i Ä‘Äƒng vÃ o há»‡ thá»‘ng (save_agent_post)
- Tra cá»©u lá»‹ch Ä‘Äƒng, pages, thá»‘ng kÃª

USER Cá»¦A Báº N LÃ€:
- NgÆ°á»i quáº£n lÃ½ nhiá»u Fanpages Facebook
- Táº¡o bÃ i Ä‘Äƒng Ä‘á»ƒ quáº£ng bÃ¡, bÃ¡n sáº£n pháº©m trÃªn Fanpages
- Cáº§n tiáº¿t kiá»‡m thá»i gian, táº¡o content cháº¥t lÆ°á»£ng

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HÃ€NH VI Cá»T LÃ•I
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. HÃ€NH Äá»˜NG NGAY - Tá»± gá»i tools, khÃ´ng há»i permission
2. SONG SONG - Gá»i nhiá»u tools cÃ¹ng lÃºc náº¿u Ä‘á»™c láº­p
3. Káº¾T QUáº¢ - Chá»‰ bÃ¡o káº¿t quáº£ cuá»‘i, khÃ´ng giáº£i thÃ­ch process

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CÃCH TÆ¯ DUY (ReAct)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Vá»›i Má»–I request, tá»± há»i:
â‘  "User muá»‘n gÃ¬?" â†’ XÃ¡c Ä‘á»‹nh goal
â‘¡ "Cáº§n data gÃ¬?" â†’ List ra
â‘¢ "Tools nÃ o cho data Ä‘Ã³?" â†’ Chá»n tools
â‘£ Gá»i tools (song song náº¿u Ä‘Æ°á»£c)
â‘¤ "Äá»§ chÆ°a?" â†’ Náº¿u chÆ°a, gá»i thÃªm

âš ï¸ KHÃ”NG response khi chÆ°a cÃ³ Ä‘á»§ data

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TOOL USAGE PATTERNS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“… Há»I Vá»€ THá»œI GIAN ("hÃ´m nay", "tuáº§n nÃ y", "ngÃ y mai"...)
   â†’ get_current_datetime + [tool liÃªn quan]

ğŸ“‹ Há»I Vá»€ Lá»ŠCH ÄÄ‚NG
   â†’ get_current_datetime + get_scheduled_posts

ğŸ“± Há»I Vá»€ PAGES/TÃ€I KHOáº¢N
   â†’ get_connected_accounts

âœï¸ Táº O BÃ€I Má»šI (tá»« topic)
   â†’ generate_post_content(topic=...)
   â†’ generate_post_image(post_content=...)
   â†’ save_agent_post(content=..., image_id=...)

ğŸ“ Táº O BÃ€I Tá»ª Lá»ŠCH (cÃ³ sáºµn draft)
   â†’ get_scheduled_posts (láº¥y draft content)
   â†’ generate_post_content(draft_content=...) [chau chuá»‘t]
   â†’ generate_post_image(post_content=...)
   â†’ save_agent_post(...)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
QUY Táº®C RESPONSE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

FORMAT:
â€¢ KHÃ”NG markdown (*, **, #, ```)
â€¢ DÃ¹ng sá»‘ (1. 2. 3.) hoáº·c gáº¡ch (-) Ä‘á»ƒ list
â€¢ Tiáº¿ng Viá»‡t tá»± nhiÃªn, thÃ¢n thiá»‡n

KHI XEM DATA:
â€¢ Liá»‡t kÃª CHI TIáº¾T: ID, tÃªn, ngÃ y, ná»™i dung preview
â€¢ TÃ³m táº¯t sá»‘ lÆ°á»£ng á»Ÿ cuá»‘i

KHI Táº O BÃ€I:
â€¢ ThÃ´ng bÃ¡o Ä‘Ã£ táº¡o thÃ nh cÃ´ng
â€¢ Hiá»ƒn thá»‹ preview content + image

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
VÃ Dá»¤ CONVERSATIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

User: "check lá»‹ch Ä‘Äƒng hÃ´m nay"
Think: Cáº§n ngÃ y hÃ´m nay + lá»‹ch Ä‘Äƒng â†’ 2 tools
Action: get_current_datetime() + get_scheduled_posts(days_ahead=0)
Response: "HÃ´m nay (03/12) cÃ³ 3 bÃ i cáº§n Ä‘Äƒng:
1. 9:00 - Giá»›i thiá»‡u sáº£n pháº©m má»›i
2. 14:00 - Tips sá»­ dá»¥ng
3. 19:00 - Khuyáº¿n mÃ£i cuá»‘i nÄƒm"

---

User: "táº¡o bÃ i vá» khuyáº¿n mÃ£i cuá»‘i nÄƒm"
Think: Táº¡o má»›i tá»« topic â†’ generate content â†’ image â†’ save
Action: generate_post_content(topic="khuyáº¿n mÃ£i cuá»‘i nÄƒm")
[Sau khi cÃ³ content]
Action: generate_post_image(post_content="...")
[Sau khi cÃ³ image]
Action: save_agent_post(content="...", image_id=123)
Response: "ÄÃ£ táº¡o bÃ i Ä‘Äƒng #45 vá» khuyáº¿n mÃ£i cuá»‘i nÄƒm vá»›i 3 hÃ¬nh áº£nh!"

---

User: "táº¡o bÃ i Ä‘Äƒng tá»« ná»™i dung trong lá»‹ch Ä‘Äƒng hÃ´m nay"
Think: Cáº§n láº¥y lá»‹ch â†’ láº¥y draft content â†’ chau chuá»‘t â†’ táº¡o áº£nh â†’ lÆ°u
Action: get_current_datetime() + get_scheduled_posts(days_ahead=0)
[CÃ³ draft tá»« lá»‹ch: "Giá»›i thiá»‡u táº¥m polycarbonate má»›i..."]
Action: generate_post_content(draft_content="Giá»›i thiá»‡u táº¥m polycarbonate má»›i...")
[CÃ³ content hoÃ n chá»‰nh]
Action: generate_post_image(post_content="...")
[CÃ³ image]
Action: save_agent_post(content="...", image_id=456)
Response: "ÄÃ£ táº¡o bÃ i Ä‘Äƒng #46 tá»« lá»‹ch Ä‘Äƒng hÃ´m nay vá»›i 3 hÃ¬nh áº£nh!"

---

User: "cÃ³ bao nhiÃªu pages"
Think: Há»i vá» pages â†’ get_connected_accounts
Action: get_connected_accounts()
Response: "Hiá»‡n cÃ³ 7 pages Facebook Ä‘ang káº¿t ná»‘i:
1. Everest Light Báº¯c Ninh (Váº­t liá»‡u xÃ¢y dá»±ng)
2. Everest Light PhÃº Thá» (Váº­t liá»‡u xÃ¢y dá»±ng)
..."
"""

        # Initialize model with function calling (model from .env)
        self.model = genai.GenerativeModel(
            model_name=model_name,
            tools=self._define_tools(),
            system_instruction=self.system_prompt
        )

        # Track token usage
        self.last_token_usage = {
            'input_tokens': 0,
            'output_tokens': 0,
            'total_tokens': 0
        }

    def count_tokens(self, text: str) -> int:
        """
        Count tokens trong text sá»­ dá»¥ng Gemini API

        Args:
            text: Text cáº§n Ä‘áº¿m tokens

        Returns:
            Sá»‘ lÆ°á»£ng tokens
        """
        try:
            result = self.model.count_tokens(text)
            return result.total_tokens
        except Exception:
            # Fallback: estimate ~4 chars per token
            return len(text) // 4

    def _define_tools(self) -> List[Dict]:
        """
        Define tools (functions) mÃ  Agent cÃ³ thá»ƒ sá»­ dá»¥ng
        Format theo Gemini API requirements (UPPERCASE types)
        """
        return [
            {
                "name": "get_current_datetime",
                "description": """Láº¥y thÃ´ng tin thá»i gian hiá»‡n táº¡i.
Cáº¦N KHI: User nÃ³i "ngÃ y mai", "hÃ´m nay", "tuáº§n sau", "thÃ¡ng nÃ y"...
TRáº¢ Vá»€: today, tomorrow, day_of_week, current_time, year, month.
THÆ¯á»œNG DÃ™NG CÃ™NG: get_scheduled_posts, get_agent_posts (khi cáº§n filter theo ngÃ y).""",
                "parameters": {
                    "type": "OBJECT",
                    "properties": {}
                }
            },
            {
                "name": "get_agent_posts",
                "description": """Láº¥y danh sÃ¡ch bÃ i Ä‘Äƒng Ä‘Ã£ Ä‘Æ°á»£c Agent táº¡o trÆ°á»›c Ä‘Ã³ tá»« database.
Cáº¦N KHI: User muá»‘n xem láº¡i posts agent Ä‘Ã£ táº¡o, kiá»ƒm tra bÃ i Ä‘Ã£ táº¡o.
TRáº¢ Vá»€: post_id, content, status, created_at, images.
THÆ¯á»œNG DÃ™NG CÃ™NG: get_current_datetime (khi filter theo ngÃ y).""",
                "parameters": {
                    "type": "OBJECT",
                    "properties": {
                        "limit": {
                            "type": "INTEGER",
                            "description": "Sá»‘ lÆ°á»£ng posts cáº§n láº¥y, máº·c Ä‘á»‹nh 20"
                        },
                        "status": {
                            "type": "STRING",
                            "description": "Filter: all, pending, completed, failed"
                        }
                    }
                }
            },
            {
                "name": "get_scheduled_posts",
                "description": """Láº¥y danh sÃ¡ch lá»‹ch Ä‘Äƒng bÃ i Ä‘Ã£ schedule tá»« database.
Cáº¦N KHI: User há»i vá» lá»‹ch Ä‘Äƒng, schedule, bÃ i Ä‘Ã£ lÃªn káº¿ hoáº¡ch.
TRáº¢ Vá»€: scheduled_date, business_type, full_content, goal, content_type.
THÆ¯á»œNG DÃ™NG CÃ™NG: get_current_datetime (khi cÃ³ tá»« thá»i gian), get_connected_accounts (khi táº¡o bÃ i cho pages).""",
                "parameters": {
                    "type": "OBJECT",
                    "properties": {
                        "status": {
                            "type": "STRING",
                            "description": "Filter: draft, approved, scheduled, published"
                        },
                        "limit": {
                            "type": "INTEGER",
                            "description": "Sá»‘ lÆ°á»£ng, máº·c Ä‘á»‹nh 10"
                        },
                        "days_ahead": {
                            "type": "INTEGER",
                            "description": "Sá»‘ ngÃ y tá»« hÃ´m nay (VD: 7 = 7 ngÃ y tá»›i)"
                        },
                        "start_date": {
                            "type": "STRING",
                            "description": "NgÃ y báº¯t Ä‘áº§u (YYYY-MM-DD)"
                        },
                        "end_date": {
                            "type": "STRING",
                            "description": "NgÃ y káº¿t thÃºc (YYYY-MM-DD)"
                        }
                    }
                }
            },
            {
                "name": "get_system_stats",
                "description": """Thá»‘ng kÃª tá»•ng quan há»‡ thá»‘ng.
KHI NÃ€O DÃ™NG: User há»i vá» stats, sá»‘ lÆ°á»£ng posts/pages/media.
INTENT: Chá»‰ XEM thá»‘ng kÃª.""",
                "parameters": {
                    "type": "OBJECT",
                    "properties": {}
                }
            },
            {
                "name": "generate_post_content",
                "description": """Táº¡o/chau chuá»‘t ná»™i dung bÃ i Ä‘Äƒng báº±ng AI.
Cáº¦N KHI: User muá»‘n táº¡o bÃ i má»›i HOáº¶C cÃ³ content nhÃ¡p cáº§n chau chuá»‘t.
TRáº¢ Vá»€: content hoÃ n chá»‰nh (150+ tá»«, tá»± nhiÃªn).
SAU KHI Gá»ŒI: Gá»i generate_post_image vá»›i content nÃ y, rá»“i save_agent_post.""",
                "parameters": {
                    "type": "OBJECT",
                    "properties": {
                        "draft_content": {
                            "type": "STRING",
                            "description": "Ná»™i dung nhÃ¡p cáº§n chau chuá»‘t (tá»« lá»‹ch hoáº·c user cung cáº¥p)"
                        },
                        "page_context": {
                            "type": "STRING",
                            "description": "TÃªn page + category Ä‘á»ƒ customize ná»™i dung. VD: 'Everest Light Báº¯c Ninh - Váº­t liá»‡u xÃ¢y dá»±ng'"
                        },
                        "topic": {
                            "type": "STRING",
                            "description": "Chá»§ Ä‘á» bÃ i Ä‘Äƒng (náº¿u khÃ´ng cÃ³ draft_content)"
                        },
                        "goal": {
                            "type": "STRING",
                            "description": "Má»¥c tiÃªu: awareness, engagement, conversion"
                        },
                        "tone": {
                            "type": "STRING",
                            "description": "Giá»ng Ä‘iá»‡u: professional, casual, friendly, funny"
                        }
                    },
                    "required": []
                }
            },
            {
                "name": "generate_post_image",
                "description": """Táº¡o hÃ¬nh áº£nh báº±ng AI phÃ¹ há»£p vá»›i content bÃ i Ä‘Äƒng.
Cáº¦N KHI: ÄÃ£ cÃ³ content hoÃ n chá»‰nh (tá»« generate_post_content) vÃ  cáº§n táº¡o áº£nh.
TRáº¢ Vá»€: image_id, image_url.
SAU KHI Gá»ŒI: Gá»i save_agent_post vá»›i content vÃ  image_id Ä‘á»ƒ lÆ°u.""",
                "parameters": {
                    "type": "OBJECT",
                    "properties": {
                        "post_content": {
                            "type": "STRING",
                            "description": "Content bÃ i Ä‘Äƒng Ä‘Ã£ generate (tá»« generate_post_content) - dÃ¹ng Ä‘á»ƒ táº¡o áº£nh phÃ¹ há»£p"
                        },
                        "page_context": {
                            "type": "STRING",
                            "description": "TÃªn page + ngÃ nh nghá» Ä‘á»ƒ customize áº£nh. VD: 'Everest Light Báº¯c Ninh - Váº­t liá»‡u xÃ¢y dá»±ng'"
                        },
                        "style": {
                            "type": "STRING",
                            "description": "Phong cÃ¡ch: professional, modern, minimalist, colorful"
                        },
                        "size": {
                            "type": "STRING",
                            "description": "KÃ­ch thÆ°á»›c: 1080x1080, 1200x628, 1080x1920"
                        }
                    },
                    "required": ["post_content"]
                }
            },
            {
                "name": "save_agent_post",
                "description": """LÆ°u bÃ i Ä‘Äƒng hoÃ n chá»‰nh vÃ o database.
Cáº¦N KHI: ÄÃ£ cÃ³ content (tá»« generate_post_content) VÃ€ image (tá»« generate_post_image).
TRáº¢ Vá»€: post_id, status, image_urls.
QUAN TRá»ŒNG: Tool nÃ y CHá»ˆ LÆ¯U, khÃ´ng generate. Pháº£i gá»i generate_post_content vÃ  generate_post_image trÆ°á»›c.""",
                "parameters": {
                    "type": "OBJECT",
                    "properties": {
                        "content": {
                            "type": "STRING",
                            "description": "Ná»™i dung Ä‘Ã£ generate tá»« generate_post_content"
                        },
                        "image_id": {
                            "type": "INTEGER",
                            "description": "ID cá»§a image Ä‘Ã£ táº¡o tá»« generate_post_image"
                        },
                        "page_context": {
                            "type": "STRING",
                            "description": "TÃªn page Ä‘á»ƒ reference. VD: 'Everest Light Báº¯c Ninh'"
                        }
                    },
                    "required": ["content"]
                }
            },
            {
                "name": "analyze_schedule",
                "description": """PhÃ¢n tÃ­ch lá»‹ch Ä‘Äƒng, Ä‘Æ°a ra insights vÃ  recommendations.
KHI NÃ€O DÃ™NG: User muá»‘n phÃ¢n tÃ­ch, Ä‘Ã¡nh giÃ¡ lá»‹ch Ä‘Äƒng.
INTENT: Chá»‰ XEM phÃ¢n tÃ­ch.""",
                "parameters": {
                    "type": "OBJECT",
                    "properties": {
                        "schedule_id": {
                            "type": "INTEGER",
                            "description": "ID cá»§a schedule cáº§n phÃ¢n tÃ­ch"
                        }
                    }
                }
            },
            {
                "name": "get_connected_accounts",
                "description": """Láº¥y danh sÃ¡ch pages/tÃ i khoáº£n máº¡ng xÃ£ há»™i Ä‘ang káº¿t ná»‘i tá»« database.
Cáº¦N KHI: User há»i vá» pages, tÃ i khoáº£n Facebook, káº¿t ná»‘i.
TRáº¢ Vá»€: name, platform, category, is_active, token_status.
THÆ¯á»œNG DÃ™NG CÃ™NG: generate_post_content (dÃ¹ng name lÃ m page_context), get_scheduled_posts (khi táº¡o bÃ i).""",
                "parameters": {
                    "type": "OBJECT",
                    "properties": {
                        "platform": {
                            "type": "STRING",
                            "description": "Filter theo platform: facebook, instagram, zalo, tiktok (máº·c Ä‘á»‹nh: táº¥t cáº£)"
                        },
                        "active_only": {
                            "type": "BOOLEAN",
                            "description": "Chá»‰ láº¥y tÃ i khoáº£n Ä‘ang active (máº·c Ä‘á»‹nh: true)"
                        }
                    }
                }
            }
        ]

    def chat(self, user_message: str, user_id: int, conversation_history: List[Dict] = None) -> Dict[str, Any]:
        """
        Chat vá»›i user vÃ  tá»± Ä‘á»™ng thá»±c hiá»‡n tasks náº¿u cáº§n

        Args:
            user_message: Tin nháº¯n tá»« user
            user_id: ID cá»§a user
            conversation_history: Lá»‹ch sá»­ há»™i thoáº¡i trÆ°á»›c Ä‘Ã³

        Returns:
            {
                'agent_response': str,
                'function_calls': List[Dict],
                'needs_tool_execution': bool
            }
        """
        try:
            # Build conversation context
            chat_history = []
            if conversation_history:
                for msg in conversation_history:
                    role = msg['role']
                    content = msg['message']
                    if role == 'user':
                        chat_history.append({'role': 'user', 'parts': [content]})
                    elif role == 'agent':
                        chat_history.append({'role': 'model', 'parts': [content]})

            # Start chat session
            chat = self.model.start_chat(history=chat_history)

            # Count input tokens (user message)
            input_tokens = self.count_tokens(user_message)

            # Add tokens from history
            for msg in chat_history:
                if msg.get('parts'):
                    for part in msg['parts']:
                        input_tokens += self.count_tokens(str(part))

            # Send user message
            response = chat.send_message(user_message)

            # Count output tokens from response
            output_tokens = 0

            # Extract function calls if any
            function_calls = []
            response_text = ""

            if response.candidates:
                candidate = response.candidates[0]
                if candidate.content and candidate.content.parts:
                    for part in candidate.content.parts:
                        # Check for function call
                        if hasattr(part, 'function_call') and part.function_call:
                            fc = part.function_call
                            # Convert args to JSON-serializable dict
                            args_dict = {}
                            if fc.args:
                                # Manually convert each arg to primitive types
                                for key in fc.args:
                                    value = fc.args[key]
                                    # Convert to primitive Python types
                                    if isinstance(value, (str, int, float, bool, type(None))):
                                        args_dict[key] = value
                                    elif isinstance(value, (list, tuple)):
                                        args_dict[key] = list(value)
                                    else:
                                        # For complex types, try to convert to string
                                        try:
                                            args_dict[key] = str(value)
                                        except:
                                            args_dict[key] = None

                            function_calls.append({
                                'name': fc.name,
                                'args': args_dict
                            })
                        # Check for text
                        elif hasattr(part, 'text') and part.text:
                            response_text += part.text
                            output_tokens += self.count_tokens(part.text)

            # Store token usage
            self.last_token_usage = {
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
                'total_tokens': input_tokens + output_tokens
            }

            return {
                'agent_response': response_text,
                'function_calls': function_calls,
                'needs_tool_execution': len(function_calls) > 0,
                'chat_session': chat,  # Return chat session for multi-turn conversation
                'raw_response': response,
                'token_usage': self.last_token_usage
            }

        except Exception as e:
            return {
                'agent_response': f"Xin lá»—i, tÃ´i gáº·p lá»—i: {str(e)}",
                'function_calls': [],
                'needs_tool_execution': False,
                'error': str(e),
                'token_usage': {'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0}
            }

    def continue_with_tool_results(self, chat_session, function_results: List[Dict], user=None) -> Dict[str, Any]:
        """
        Tiáº¿p tá»¥c conversation sau khi execute tools

        Args:
            chat_session: Gemini chat session
            function_results: Káº¿t quáº£ tá»« cÃ¡c function calls
            user: User object for executing additional tools

        Returns:
            {
                'response': str,
                'token_usage': {'input_tokens': int, 'output_tokens': int, 'total_tokens': int}
            }
        """
        try:
            # Track tokens for this turn
            input_tokens = 0
            output_tokens = 0

            # Create function response parts
            parts = []
            for result in function_results:
                # Count tokens from function results
                result_str = str(result.get('result', ''))
                input_tokens += self.count_tokens(result_str)

                parts.append(
                    genai.protos.Part(
                        function_response=genai.protos.FunctionResponse(
                            name=result['function_name'],
                            response={'result': result['result']}
                        )
                    )
                )

            # Send function results back to model
            response = chat_session.send_message(
                genai.protos.Content(parts=parts)
            )

            # Check for errors (malformed function call, etc)
            import logging
            logger = logging.getLogger(__name__)

            if response.candidates and response.candidates[0].finish_reason:
                finish_reason = str(response.candidates[0].finish_reason)
                if 'MALFORMED' in finish_reason or 'ERROR' in finish_reason:
                    logger.error(f"[AGENT] Model returned error: {finish_reason}")
                    logger.error(f"[AGENT] Response content: {response.candidates[0].content if response.candidates[0].content else 'None'}")
                    return {
                        'response': "ÄÃ£ hoÃ n thÃ nh xá»­ lÃ½ cÃ¡c bÆ°á»›c trÆ°á»›c Ä‘Ã³.",
                        'token_usage': {'input_tokens': input_tokens, 'output_tokens': 0, 'total_tokens': input_tokens}
                    }

            # Check if model wants to call MORE functions
            if response.candidates and response.candidates[0].content:
                parts_list = response.candidates[0].content.parts

                # Check for more function calls
                more_function_calls = []
                for part in parts_list:
                    if hasattr(part, 'function_call') and part.function_call:
                        fc = part.function_call
                        args_dict = {}
                        if fc.args:
                            for key in fc.args:
                                value = fc.args[key]
                                # Convert to primitive Python types (same logic as chat method)
                                if isinstance(value, (str, int, float, bool, type(None))):
                                    args_dict[key] = value
                                elif isinstance(value, (list, tuple)):
                                    args_dict[key] = list(value)
                                else:
                                    try:
                                        args_dict[key] = str(value)
                                    except:
                                        args_dict[key] = None

                        more_function_calls.append({
                            'name': fc.name,
                            'args': args_dict
                        })

                # If there are more function calls, execute them too!
                if more_function_calls:
                    import logging
                    logger = logging.getLogger(__name__)
                    logger.info(f"[AGENT] Model wants to call {len(more_function_calls)} more functions: {[fc['name'] for fc in more_function_calls]}")

                    # Check if we have user context
                    if not user:
                        logger.error("[AGENT] Cannot execute additional tools - user context missing")
                        return {
                            'response': "ÄÃ£ xá»­ lÃ½ xong pháº§n Ä‘áº§u, nhÆ°ng khÃ´ng thá»ƒ tiáº¿p tá»¥c.",
                            'token_usage': {'input_tokens': input_tokens, 'output_tokens': 0, 'total_tokens': input_tokens}
                        }

                    # Execute additional tools
                    from .services import AgentToolExecutor

                    additional_results = []
                    for fc in more_function_calls:
                        logger.info(f"[AGENT] Executing additional tool: {fc['name']}")
                        result = AgentToolExecutor.execute_tool(
                            function_name=fc['name'],
                            arguments=fc['args'],
                            user=user
                        )
                        additional_results.append({
                            'function_name': fc['name'],
                            'result': result
                        })

                    # RECURSIVELY continue with additional tool results
                    recursive_result = self.continue_with_tool_results(
                        chat_session=chat_session,
                        function_results=additional_results,
                        user=user
                    )
                    # Add current input tokens to recursive result
                    recursive_result['token_usage']['input_tokens'] += input_tokens
                    recursive_result['token_usage']['total_tokens'] += input_tokens
                    return recursive_result

                # Extract text response and count output tokens
                text_parts = []
                for p in parts_list:
                    if hasattr(p, 'text') and p.text:
                        text_parts.append(p.text)
                        output_tokens += self.count_tokens(p.text)

                response_text = '\n'.join(text_parts) if text_parts else "ÄÃ£ xá»­ lÃ½ xong!"

                # Update stored token usage
                self.last_token_usage = {
                    'input_tokens': self.last_token_usage.get('input_tokens', 0) + input_tokens,
                    'output_tokens': self.last_token_usage.get('output_tokens', 0) + output_tokens,
                    'total_tokens': self.last_token_usage.get('input_tokens', 0) + input_tokens + self.last_token_usage.get('output_tokens', 0) + output_tokens
                }

                return {
                    'response': response_text,
                    'token_usage': self.last_token_usage
                }

            return {
                'response': "ÄÃ£ xá»­ lÃ½ xong!",
                'token_usage': self.last_token_usage
            }

        except Exception as e:
            return {
                'response': f"Lá»—i khi xá»­ lÃ½: {str(e)}",
                'token_usage': self.last_token_usage
            }

    def generate_post_automatically(
        self,
        business_type: str,
        topic: str,
        goal: str = 'engagement',
        user_id: int = None
    ) -> Dict[str, Any]:
        """
        Tá»± Ä‘á»™ng generate má»™t post hoÃ n chá»‰nh (content + image)

        Args:
            business_type: Loáº¡i hÃ¬nh kinh doanh
            topic: Chá»§ Ä‘á»
            goal: Má»¥c tiÃªu
            user_id: ID cá»§a user

        Returns:
            {
                'content': str,
                'hashtags': List[str],
                'image_url': str,
                'reasoning': str
            }
        """
        prompt = f"""
HÃ£y táº¡o má»™t bÃ i Ä‘Äƒng Facebook hoÃ n chá»‰nh vá»›i thÃ´ng tin sau:

Business: {business_type}
Topic: {topic}
Goal: {goal}

YÃªu cáº§u:
1. Táº¡o content háº¥p dáº«n, cÃ³ hook máº¡nh
2. Táº¡o hÃ¬nh áº£nh phÃ¹ há»£p
3. Include hashtags relevant

HÃ£y sá»­ dá»¥ng tools Ä‘á»ƒ táº¡o post hoÃ n chá»‰nh!
"""

        # Start chat
        chat = self.model.start_chat()
        response = chat.send_message(prompt)

        # Agent sáº½ tá»± Ä‘á»™ng gá»i tools
        # Return response Ä‘á»ƒ service layer xá»­ lÃ½
        return {
            'chat_session': chat,
            'initial_response': response
        }


# Singleton instance
_agent_instance = None


def get_agent() -> GeminiAgent:
    """Get or create agent instance"""
    global _agent_instance
    if _agent_instance is None:
        _agent_instance = GeminiAgent()
    return _agent_instance
