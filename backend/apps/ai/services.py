"""
AI Content Generation Service
Supports multiple AI providers: Google Gemini and DeepSeek
"""
from decouple import config
from django.core.exceptions import ValidationError
import logging
import re

logger = logging.getLogger(__name__)


def clean_markdown_content(content: str) -> str:
    """
    Lo·∫°i b·ªè markdown formatting kh·ªèi content.
    Facebook kh√¥ng h·ªó tr·ª£ markdown, c·∫ßn plain text.

    Args:
        content: N·ªôi dung c√≥ th·ªÉ ch·ª©a markdown

    Returns:
        Content ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch markdown
    """
    if not content:
        return content

    # Remove bold: **text** ho·∫∑c __text__
    content = re.sub(r'\*\*(.+?)\*\*', r'\1', content)
    content = re.sub(r'__(.+?)__', r'\1', content)

    # Remove italic: *text* ho·∫∑c _text_
    content = re.sub(r'(?<!\*)\*(?!\*)(.+?)(?<!\*)\*(?!\*)', r'\1', content)
    content = re.sub(r'(?<!_)_(?!_)(.+?)(?<!_)_(?!_)', r'\1', content)

    # Remove strikethrough: ~~text~~
    content = re.sub(r'~~(.+?)~~', r'\1', content)

    # Remove inline code: `text`
    content = re.sub(r'`(.+?)`', r'\1', content)

    # Remove markdown headers: # ## ### etc
    content = re.sub(r'^#{1,6}\s+', '', content, flags=re.MULTILINE)

    # Remove markdown links: [text](url) -> text
    content = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', content)

    # Remove markdown images: ![alt](url)
    content = re.sub(r'!\[([^\]]*)\]\([^\)]+\)', r'\1', content)

    # Clean up extra whitespace
    content = re.sub(r'\n{3,}', '\n\n', content)

    return content.strip()


def get_ai_provider() -> str:
    """Get configured AI provider from settings"""
    return config('AI_AGENT_PROVIDER', default='gemini').lower()


def get_text_model_config():
    """
    Get AI client and model name based on configured provider

    Returns:
        tuple: (client, model_name, provider)
    """
    provider = get_ai_provider()

    if provider == 'deepseek':
        from openai import OpenAI
        import httpx

        api_key = config('DEEPSEEK_API_KEY', default='')
        if not api_key:
            raise ValidationError("DEEPSEEK_API_KEY is not configured")

        # Increase timeout for long responses (schedule generation needs more time)
        client = OpenAI(
            api_key=api_key,
            base_url="https://api.deepseek.com",
            timeout=httpx.Timeout(120.0, connect=10.0)  # 120s total, 10s connect
        )
        model_name = config('DEEPSEEK_TEXT_MODEL', default='deepseek-chat')

        logger.info(f"[AI] Using DeepSeek provider with model: {model_name}")
        return client, model_name, 'deepseek'

    else:  # Default to Gemini
        from google import genai

        api_key = config('GEMINI_API_KEY', default='')
        if not api_key:
            raise ValidationError("GEMINI_API_KEY is not configured")

        client = genai.Client(api_key=api_key)
        model_name = config('GEMINI_TEXT_MODEL', default='gemini-2.0-flash')

        logger.info(f"[AI] Using Gemini provider with model: {model_name}")
        return client, model_name, 'gemini'


def generate_text_with_provider(prompt: str, client, model_name: str, provider: str, max_tokens: int = None) -> str:
    """
    Generate text using the configured AI provider

    Args:
        prompt: The prompt to send to the AI
        client: AI client instance
        model_name: Model name to use
        provider: Provider name ('gemini' or 'deepseek')
        max_tokens: Maximum tokens for response. If None, uses max available for model.
                    DeepSeek: up to 8192 for deepseek-chat, 16384 for deepseek-reasoner

    Returns:
        str: Generated text response
    """
    if provider == 'deepseek':
        # DeepSeek default max_tokens is low, set high to avoid truncation
        # deepseek-chat supports up to 8192, deepseek-reasoner up to 16384
        if max_tokens is None:
            if 'reasoner' in model_name:
                max_tokens = 16384
            else:
                max_tokens = 8192

        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "user", "content": prompt}
            ],
            max_tokens=max_tokens
        )
        return response.choices[0].message.content.strip()

    else:  # Gemini - no max_tokens needed, handles long content well
        response = client.models.generate_content(
            model=model_name,
            contents=prompt
        )
        return response.text.strip()


class AIContentService:
    """Service for AI-powered content generation - supports Gemini and DeepSeek"""

    @staticmethod
    def generate_content(
        prompt: str,
        tone: str = 'professional',
        include_hashtags: bool = True,
        include_emoji: bool = True,
        language: str = 'vi'
    ) -> dict:
        """
        Generate post content using configured AI provider (Gemini or DeepSeek)

        Args:
            prompt: Text prompt describing the content to generate
            tone: Tone of content ('professional', 'casual', 'funny', 'formal')
            include_hashtags: Whether to include hashtags
            include_emoji: Whether to include emojis
            language: Language code ('vi' for Vietnamese, 'en' for English)

        Returns:
            dict: Generated content information
        """
        # Get AI client based on configured provider
        client, model_name, provider = get_text_model_config()

        # Map tone to Vietnamese instructions
        tone_map = {
            'professional': 'chuy√™n nghi·ªáp, l·ªãch s·ª±, ƒë√°ng tin c·∫≠y',
            'casual': 'th√¢n thi·ªán, g·∫ßn g≈©i, tho·∫£i m√°i',
            'funny': 'h√†i h∆∞·ªõc, vui nh·ªôn, d√≠ d·ªèm',
            'formal': 'trang tr·ªçng, nghi√™m t√∫c, ch√≠nh th·ª©c'
        }
        tone_instruction = tone_map.get(tone, tone_map['professional'])

        # Build the prompt
        language_instruction = 'ti·∫øng Vi·ªát t·ª± nhi√™n' if language == 'vi' else 'English'
        hashtag_instruction = 'Th√™m 3-5 hashtag chi·∫øn l∆∞·ª£c (mix ph·ªï bi·∫øn + niche) ·ªü cu·ªëi b√†i.' if include_hashtags else 'Kh√¥ng th√™m hashtag.'
        emoji_instruction = 'S·ª≠ d·ª•ng 3-5 emoji ph√π h·ª£p ƒë·ªÉ tƒÉng t∆∞∆°ng t√°c v√† break text.' if include_emoji else 'H·∫°n ch·∫ø emoji.'

        system_prompt = f"""B·∫†N L√Ä CHUY√äN GIA SOCIAL MEDIA MARKETING v·ªõi h∆°n 10 nƒÉm kinh nghi·ªám qu·∫£n l√Ω fanpage cho c√°c th∆∞∆°ng hi·ªáu l·ªõn t·∫°i Vi·ªát Nam.

NƒÇNG L·ª∞C C·ª¶A B·∫†N:
- T·∫°o n·ªôi dung viral, c√≥ t√≠nh t∆∞∆°ng t√°c cao
- Ph√¢n t√≠ch insight v√† t√¢m l√Ω ng∆∞·ªùi d√πng Facebook/Instagram
- T·ªëi ∆∞u SEO v√† thu·∫≠t to√°n m·∫°ng x√£ h·ªôi
- Vi·∫øt content thu h√∫t, k·∫øt n·ªëi c·∫£m x√∫c v·ªõi ng∆∞·ªùi ƒë·ªçc

NHI·ªÜM V·ª§: T·∫†O B√ÄI ƒêƒÇNG CH·∫§T L∆Ø·ª¢NG CAO

H√£y t·∫°o n·ªôi dung b√†i ƒëƒÉng v·ªõi c·∫•u tr√∫c t·ªëi ∆∞u:

1. HOOK (2-3 d√≤ng ƒë·∫ßu):
   - G√¢y ch√∫ √Ω ngay l·∫≠p t·ª©c (quan tr·ªçng nh·∫•t v√¨ FB c·∫Øt preview)
   - T·∫°o t√≤ m√≤ ho·∫∑c c·∫£m x√∫c m·∫°nh
   - B·∫ÆT ƒê·∫¶U B√ÄI VI·∫æT NGAY v·ªõi hook, KH√îNG ghi ch·ªØ "Hook:"

2. BODY (N·ªôi dung ch√≠nh):
   - Storytelling ho·∫∑c th√¥ng tin gi√° tr·ªã
   - Chia ƒëo·∫°n ng·∫Øn, d·ªÖ ƒë·ªçc (2-3 d√≤ng/ƒëo·∫°n)
   - T·∫°o k·∫øt n·ªëi v·ªõi ng∆∞·ªùi ƒë·ªçc
   - CHUY·ªÇN TI·∫æP T·ª∞ NHI√äN t·ª´ hook, KH√îNG ghi ch·ªØ "Body:"

3. ENGAGEMENT (T∆∞∆°ng t√°c):
   - ƒê·∫∑t c√¢u h·ªèi ƒë·ªÉ khuy·∫øn kh√≠ch comment
   - T·∫°o discussion point
   - VI·∫æT TH·∫≤NG c√¢u h·ªèi, KH√îNG ghi ch·ªØ "Engagement:"

4. CTA (Call-to-Action):
   - K√™u g·ªçi h√†nh ƒë·ªông r√µ r√†ng
   - Ph√π h·ª£p v·ªõi m·ª•c ƒë√≠ch b√†i ƒëƒÉng
   - VI·∫æT TH·∫≤NG l·ªùi k√™u g·ªçi, KH√îNG ghi ch·ªØ "CTA:"

5. HASHTAG:
   - ƒê·∫∑t ·ªü cu·ªëi b√†i, c√°ch 1 d√≤ng tr·ªëng
   - Mix hashtag ph·ªï bi·∫øn + niche
   - CH·ªà GHI C√ÅC HASHTAG, KH√îNG ghi ch·ªØ "Hashtags:"

=== Y√äU C·∫¶U T·ª™ KH√ÅCH H√ÄNG ===
{prompt}

=== H∆Ø·ªöNG D·∫™N ===
- Ng√¥n ng·ªØ: {language_instruction}
- Gi·ªçng ƒëi·ªáu: {tone_instruction}
- {emoji_instruction}
- {hashtag_instruction}

=== L∆ØU √ù QUAN TR·ªåNG ===
- Vi·∫øt nh∆∞ NG∆Ø·ªúI TH·∫¨T ƒëang chia s·∫ª, kh√¥ng nh∆∞ robot
- T·∫°o C·∫¢M X√öC v√† K·∫æT N·ªêI v·ªõi ng∆∞·ªùi ƒë·ªçc
- T·ªëi ∆∞u cho thu·∫≠t to√°n Facebook 2024
- Format d·ªÖ ƒë·ªçc tr√™n mobile
- QUAN TR·ªåNG: KH√îNG ƒê∆Ø·ª¢C ghi c√°c label nh∆∞ "Hook:", "Body:", "Engagement:", "CTA:", "Hashtags:"
- N·ªôi dung ph·∫£i CH·∫¢Y T·ª∞ NHI√äN t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi nh∆∞ m·ªôt b√†i ƒëƒÉng th·∫≠t

‚õî‚õî‚õî QUY T·∫ÆC B·∫¢O V·ªÜ TH∆Ø∆†NG HI·ªÜU - B·∫ÆT BU·ªòC TU√ÇN TH·ª¶:
- TUY·ªÜT ƒê·ªêI KH√îNG vi·∫øt b·∫•t c·ª© ƒëi·ªÅu g√¨ ti√™u c·ª±c, b·∫•t l·ª£i v·ªÅ s·∫£n ph·∫©m/d·ªãch v·ª•
- KH√îNG nh·∫Øc ƒë·∫øn ƒëi·ªÉm y·∫øu, h·∫°n ch·∫ø, khuy·∫øt ƒëi·ªÉm c·ªßa s·∫£n ph·∫©m
- KH√îNG so s√°nh ti√™u c·ª±c v·ªõi ƒë·ªëi th·ªß
- KH√îNG d√πng t·ª´ ng·ªØ g√¢y nghi ng·ªù v·ªÅ ch·∫•t l∆∞·ª£ng (c√≥ th·ªÉ, c√≥ l·∫Ω, t·∫°m ·ªïn, ch·∫•p nh·∫≠n ƒë∆∞·ª£c...)
- N·ªôi dung ph·∫£i CH√ÇN TH·ª∞C nh∆∞ng lu√¥n T√îN VINH ∆∞u ƒëi·ªÉm, gi√° tr·ªã c·ªßa s·∫£n ph·∫©m
- T·∫≠p trung v√†o l·ª£i √≠ch kh√°ch h√†ng nh·∫≠n ƒë∆∞·ª£c, kh√¥ng t·∫≠p trung v√†o t√≠nh nƒÉng kh√¥ khan
- X√¢y d·ª±ng NI·ªÄM TIN v√† S·ª∞ TIN T∆Ø·ªûNG c·ªßa kh√°ch h√†ng

CH·ªà TR·∫¢ V·ªÄ N·ªòI DUNG B√ÄI VI·∫æT HO√ÄN CH·ªàNH, KH√îNG GI·∫¢I TH√çCH TH√äM."""

        try:
            # Generate content using configured provider
            generated_content = generate_text_with_provider(
                prompt=system_prompt,
                client=client,
                model_name=model_name,
                provider=provider
            )

            # Clean markdown t·ª´ content (Facebook kh√¥ng h·ªó tr·ª£ markdown)
            generated_content = clean_markdown_content(generated_content)

            return {
                'content': generated_content,
                'tone': tone,
                'model': model_name,
                'provider': provider,
                'success': True
            }

        except Exception as e:
            raise ValidationError(f"AI content generation failed: {str(e)}")

    @staticmethod
    def generate_hashtags(content: str, count: int = 5) -> dict:
        """
        Generate relevant hashtags for content using configured AI provider

        Args:
            content: Post content
            count: Number of hashtags to generate

        Returns:
            dict: Generated hashtags
        """
        # Get AI client based on configured provider
        client, model_name, provider = get_text_model_config()

        prompt = f"""
                    D·ª±a tr√™n n·ªôi dung sau, h√£y t·∫°o {count} hashtag ph√π h·ª£p ƒë·ªÉ ƒëƒÉng Facebook:

                    N·ªòI DUNG:
                    {content}

                    Y√äU C·∫¶U:
                    - T·∫°o {count} hashtag li√™n quan ƒë·∫øn n·ªôi dung
                    - K·∫øt h·ª£p hashtag ph·ªï bi·∫øn v√† hashtag niche
                    - M·ªói hashtag tr√™n m·ªôt d√≤ng, b·∫Øt ƒë·∫ßu b·∫±ng d·∫•u #
                    - Kh√¥ng gi·∫£i th√≠ch, ch·ªâ tr·∫£ v·ªÅ danh s√°ch hashtag
                    """

        try:
            response_text = generate_text_with_provider(
                prompt=prompt,
                client=client,
                model_name=model_name,
                provider=provider
            )

            # Parse hashtags from response
            hashtags = []
            for line in response_text.split('\n'):
                line = line.strip()
                if line.startswith('#'):
                    hashtags.append(line)

            return {
                'hashtags': hashtags[:count],
                'model': model_name,
                'provider': provider,
                'success': True
            }

        except Exception as e:
            raise ValidationError(f"Hashtag generation failed: {str(e)}")

    @staticmethod
    def generate_posting_schedule(
        business_type: str,
        goals: str,
        start_date: str,
        duration: str = '1_week',
        posts_per_day: int = 2,
        language: str = 'vi'
    ) -> dict:
        """
        Generate a detailed posting schedule with specific dates and times
        Uses configured AI provider (Gemini or DeepSeek)

        Args:
            business_type: Type of business/industry
            goals: Marketing goals (awareness, engagement, sales, etc.)
            start_date: Start date for the schedule (format: YYYY-MM-DD)
            duration: Schedule duration ('1_week', '2_weeks', '1_month')
            posts_per_day: Number of posts per day
            language: Language code

        Returns:
            dict: Detailed posting schedule with dates and times
        """
        from datetime import datetime

        # Get AI client based on configured provider
        client, model_name, provider = get_text_model_config()

        duration_map = {
            '1_week': '7 ng√†y',
            '2_weeks': '14 ng√†y',
            '1_month': '30 ng√†y'
        }
        duration_text = duration_map.get(duration, '7 ng√†y')

        # Parse start date
        try:
            start = datetime.strptime(start_date, '%Y-%m-%d')
            start_formatted = start.strftime('%d/%m/%Y')
        except:
            start_formatted = start_date

        # Calculate number of days and total posts
        duration_days_map = {
            '1_week': 7,
            '2_weeks': 14,
            '1_month': 30
        }
        total_days = duration_days_map.get(duration, 7)
        total_posts = total_days * posts_per_day

        # Generate random seed for variation
        import random
        variation_seed = random.randint(1000, 9999)

        # Random content type order to avoid fixed patterns
        content_types = ['pain_point', 'educational', 'social_proof', 'engagement', 'conversion', 'lifestyle', 'promo', 'tips', 'behind_the_scenes', 'user_generated', 'trending', 'storytelling']
        random.shuffle(content_types)
        suggested_types = ', '.join(content_types[:7])

        prompt = f"""B·∫°n l√† CHUY√äN GIA MARKETING & SOCIAL MEDIA v·ªõi h∆°n 10 nƒÉm kinh nghi·ªám qu·∫£n l√Ω fanpage cho c√°c th∆∞∆°ng hi·ªáu l·ªõn t·∫°i Vi·ªát Nam.

=== NHI·ªÜM V·ª§: T·∫†O L·ªäCH ƒêƒÇNG B√ÄI JSON FORMAT ===

üé≤ VARIATION SEED: {variation_seed} (D√πng seed n√†y ƒë·ªÉ t·∫°o n·ªôi dung KH√ÅC BI·ªÜT ho√†n to√†n v·ªõi c√°c l·ªãch kh√°c)

TH√îNG TIN:
- Ng√†nh: {business_type}
- M·ª•c ti√™u: {goals}
- Ng√†y b·∫Øt ƒë·∫ßu: {start_date} (YYYY-MM-DD format)
- T·ªïng s·ªë ng√†y: {total_days}
- T·ªïng s·ªë b√†i: {total_posts} b√†i ({posts_per_day} b√†i/ng√†y)

‚ö†Ô∏è QUAN TR·ªåNG - TR√ÅNH L·∫∂P L·∫†I:
- KH√îNG theo pattern c·ªë ƒë·ªãnh (VD: ng√†y 1 lu√¥n l√† gi·ªõi thi·ªáu, ng√†y 6 lu√¥n l√† ∆∞u ƒë√£i)
- M·ªói l·ªãch tr√¨nh ph·∫£i c√≥ TH·ª® T·ª∞ content_type KH√ÅC NHAU
- G·ª£i √Ω th·ª© t·ª± cho l·ªãch n√†y: {suggested_types}
- M·ªói b√†i ph·∫£i c√≥ G√ìC NH√åN v√† CH·ª¶ ƒê·ªÄ C·ª§ TH·ªÇ kh√°c nhau

Y√äU C·∫¶U: T·∫°o l·ªãch ƒëƒÉng b√†i ·ªü ƒë·ªãnh d·∫°ng JSON v·ªõi c·∫•u tr√∫c sau:

{{
  "schedule_summary": {{
    "business_type": "{business_type}",
    "duration": "{duration_text}",
    "total_posts": {total_posts},
    "strategy_overview": "T√≥m t·∫Øt chi·∫øn l∆∞·ª£c content (2-3 c√¢u)"
  }},
  "posts": [
    {{
      "date": "YYYY-MM-DD",
      "time": "HH:MM",
      "day_of_week": "Th·ª© 2/3/4/5/6/7/CN",
      "content_type": "pain_point/educational/social_proof/engagement/conversion/lifestyle/promo/tips/behind_the_scenes/trending/storytelling",
      "title": "Ti√™u ƒë·ªÅ C·ª§ TH·ªÇ v√† H·∫§P D·∫™N (VD: '5 l·ªói ph·ªï bi·∫øn khi ch·ªçn X', 'Kh√°ch h√†ng A ƒë√£ ti·∫øt ki·ªám 30% nh·ªù...')",
      "hook": "3-4 d√≤ng ƒë·∫ßu g√¢y SHOCK ho·∫∑c T√í M√í m·∫°nh, c√≥ s·ªë li·ªáu ho·∫∑c c√¢u h·ªèi",
      "body": "N·ªôi dung ch√≠nh 100-150 t·ª´, storytelling ho·∫∑c th√¥ng tin gi√° tr·ªã C·ª§ TH·ªÇ. Chia ƒëo·∫°n ng·∫Øn.",
      "engagement": "C√¢u h·ªèi ƒë·ªÉ khuy·∫øn kh√≠ch comment v√† t∆∞∆°ng t√°c",
      "cta": "K√™u g·ªçi h√†nh ƒë·ªông r√µ r√†ng (Comment/Share/Save/Click/Inbox)",
      "hashtags": ["#hashtag1", "#hashtag2", "#hashtag3"],
      "media_type": "image/video/carousel/text",
      "goal": "awareness/engagement/conversion/retention"
    }}
  ],
  "hashtag_suggestions": ["#hashtag1", "#hashtag2", ...],
  "engagement_tips": "Tips tƒÉng reach v√† engagement (2-3 c√¢u)"
}}

L∆ØU √ù QUAN TR·ªåNG:
- T·∫°o ƒê√öNG {total_posts} b√†i ƒëƒÉng, ph√¢n b·ªï ƒë·ªÅu trong {total_days} ng√†y
- M·ªói ng√†y c√≥ {posts_per_day} b√†i, ph√¢n b·ªï th·ªùi gian h·ª£p l√Ω (s√°ng/tr∆∞a/chi·ªÅu/t·ªëi)
- Ng√†y ƒë·∫ßu ti√™n b·∫Øt ƒë·∫ßu t·ª´ {start_date}
- ‚ö†Ô∏è KH√îNG L·∫∂P L·∫†I PATTERN: Th·ª© t·ª± content_type ph·∫£i NG·∫™U NHI√äN theo g·ª£i √Ω ·ªü tr√™n
- ‚ö†Ô∏è M·ªñI B√ÄI C·∫¶N CH·ª¶ ƒê·ªÄ C·ª§ TH·ªÇ: VD thay v√¨ "Tips s·ª≠ d·ª•ng" ‚Üí "3 sai l·∫ßm khi ch·ªçn [s·∫£n ph·∫©m] khi·∫øn b·∫°n m·∫•t ti·ªÅn oan"
- N·ªôi dung hook (3-4 d√≤ng), body (100-150 t·ª´), engagement, cta ph·∫£i c·ª• th·ªÉ, KH√îNG ƒë·ªÉ placeholder
- Hashtags ph√π h·ª£p v·ªõi ng√†nh {business_type}
- CH·ªà TR·∫¢ V·ªÄ JSON, KH√îNG GI·∫¢I TH√çCH TH√äM

Ng√¥n ng·ªØ n·ªôi dung: {'Ti·∫øng Vi·ªát' if language == 'vi' else 'English'}"""

        try:
            # Generate schedule using configured provider
            response_text = generate_text_with_provider(
                prompt=prompt,
                client=client,
                model_name=model_name,
                provider=provider
            )

            # Parse JSON response
            import json
            import re

            # Try to extract JSON from response (AI might wrap it in markdown code blocks)
            json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # Try to find JSON object directly
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                else:
                    json_str = response_text

            # Check if response looks truncated (incomplete JSON)
            json_str = json_str.strip()
            if not json_str.endswith('}'):
                # Response was truncated - retry with shorter request or raise clear error
                raise ValidationError(
                    f"AI response was truncated (incomplete JSON). "
                    f"Try reducing posts_per_day or duration. "
                    f"Last 100 chars: ...{response_text[-100:]}"
                )

            try:
                schedule_data = json.loads(json_str)
            except json.JSONDecodeError as e:
                # If JSON parsing fails, return raw text in error
                raise ValidationError(f"AI response is not valid JSON: {str(e)}. Response: {response_text[:500]}")

            # Validate required fields
            if 'posts' not in schedule_data or not isinstance(schedule_data['posts'], list):
                raise ValidationError("AI response missing 'posts' array")

            return {
                'schedule_summary': schedule_data.get('schedule_summary', {}),
                'posts': schedule_data.get('posts', []),
                'hashtag_suggestions': schedule_data.get('hashtag_suggestions', []),
                'engagement_tips': schedule_data.get('engagement_tips', ''),
                'model': model_name,
                'provider': provider,
                'success': True
            }

        except ValidationError:
            raise
        except Exception as e:
            raise ValidationError(f"Schedule generation failed: {str(e)}")

    @staticmethod
    def generate_content_from_images(
        image_descriptions: list,
        user_prompt: str,
        tone: str = 'casual',
        include_hashtags: bool = True,
        language: str = 'vi'
    ) -> dict:
        """
        Generate high-quality post content based on images and user prompt
        Uses configured AI provider (Gemini or DeepSeek)

        Args:
            image_descriptions: List of image descriptions
            user_prompt: Additional prompt/instructions from user
            tone: Content tone
            include_hashtags: Whether to include hashtags
            language: Language code

        Returns:
            dict: Generated content
        """
        # Get AI client based on configured provider
        client, model_name, provider = get_text_model_config()

        # Format image descriptions
        images_text = ""
        for i, desc in enumerate(image_descriptions, 1):
            images_text += f"   H√¨nh {i}: {desc}\n"

        tone_map = {
            'professional': 'chuy√™n nghi·ªáp, ƒë√°ng tin c·∫≠y',
            'casual': 'th√¢n thi·ªán, g·∫ßn g≈©i',
            'funny': 'h√†i h∆∞·ªõc, vui nh·ªôn',
            'inspiring': 'truy·ªÅn c·∫£m h·ª©ng, t√≠ch c·ª±c',
            'emotional': 'c·∫£m x√∫c, ch·∫°m ƒë·∫øn tr√°i tim'
        }
        tone_instruction = tone_map.get(tone, tone_map['casual'])

        hashtag_instruction = """
5. HASHTAG (3-5 tags):
   - Mix hashtag ph·ªï bi·∫øn + niche
   - ƒê·∫∑t ·ªü cu·ªëi b√†i""" if include_hashtags else ""

        prompt = f"""B·∫°n l√† CHUY√äN GIA CONTENT MARKETING v·ªõi kh·∫£ nƒÉng t·∫°o n·ªôi dung viral tr√™n Facebook/Instagram.

=== NHI·ªÜM V·ª§: T·∫†O B√ÄI ƒêƒÇNG CH·∫§T L∆Ø·ª¢NG CAO ===

H√åNH ·∫¢NH ƒê√çNH K√àM:
{images_text}

Y√äU C·∫¶U T·ª™ KH√ÅCH H√ÄNG:
{user_prompt}

GI·ªåNG ƒêI·ªÜU: {tone_instruction}
NG√îN NG·ªÆ: {'Ti·∫øng Vi·ªát t·ª± nhi√™n' if language == 'vi' else 'Natural English'}

C·∫§U TR√öC B√ÄI VI·∫æT T·ªêI ∆ØU:

1. HOOK (2 d√≤ng ƒë·∫ßu - QUAN TR·ªåNG NH·∫§T):
   - G√¢y t√≤ m√≤/shock/c·∫£m x√∫c ngay l·∫≠p t·ª©c
   - Li√™n k·∫øt v·ªõi h√¨nh ·∫£nh
   - Khi·∫øn ng∆∞·ªùi ƒë·ªçc mu·ªën xem ti·∫øp

2. BODY (N·ªôi dung ch√≠nh):
   - Storytelling k·∫øt n·ªëi v·ªõi h√¨nh
   - Chia ƒëo·∫°n ng·∫Øn (2-3 d√≤ng/ƒëo·∫°n)
   - Highlight ƒëi·ªÉm n·ªïi b·∫≠t
   - T·∫°o value cho ng∆∞·ªùi ƒë·ªçc

3. ENGAGEMENT (T∆∞∆°ng t√°c):
   - ƒê·∫∑t c√¢u h·ªèi ƒë·ªÉ tƒÉng comment
   - T·∫°o discussion point

4. CTA (Call-to-Action):
   - K√™u g·ªçi h√†nh ƒë·ªông r√µ r√†ng
   - Ph√π h·ª£p v·ªõi m·ª•c ƒë√≠ch b√†i ƒëƒÉng
{hashtag_instruction}

Y√äU C·∫¶U FORMAT:
- S·ª≠ d·ª•ng emoji ph√π h·ª£p (kh√¥ng spam)
- Line break h·ª£p l√Ω
- D·ªÖ ƒë·ªçc tr√™n mobile
- ƒê·ªô d√†i: 100-200 t·ª´

CH·ªà TR·∫¢ V·ªÄ N·ªòI DUNG B√ÄI VI·∫æT HO√ÄN CH·ªàNH, KH√îNG GI·∫¢I TH√çCH."""

        try:
            # Generate content using configured provider
            generated_content = generate_text_with_provider(
                prompt=prompt,
                client=client,
                model_name=model_name,
                provider=provider
            )

            # Clean markdown t·ª´ content (Facebook kh√¥ng h·ªó tr·ª£ markdown)
            generated_content = clean_markdown_content(generated_content)

            return {
                'content': generated_content,
                'image_count': len(image_descriptions),
                'tone': tone,
                'model': model_name,
                'provider': provider,
                'success': True
            }

        except Exception as e:
            raise ValidationError(f"Content generation failed: {str(e)}")


class AIImageService:
    """Service for AI-powered image generation using Google Gemini"""

    # Image size configurations - Facebook optimized 2024
    # Based on Facebook guidelines:
    # - 1080x1080 (1:1): Square, most consistent
    # - 1080x1350 (4:5): Portrait, best for mobile engagement
    # - 1920x1080 (16:9): Landscape, standard video ratio
    # - 1200x628 (1.91:1): Link preview standard
    SIZE_CONFIGS = {
        # Facebook optimized sizes 2024
        '1080x1080': (1080, 1080),   # Square 1:1
        '1080x1350': (1080, 1350),   # Portrait 4:5 - BEST FOR MOBILE
        '1200x628': (1200, 628),     # Link preview 1.91:1
        '1080x1920': (1080, 1920),   # Story 9:16
        '1920x1080': (1920, 1080),   # Landscape 16:9
        # Legacy/other sizes
        '1200x630': (1200, 630),     # Old link preview
        '1000x1000': (1000, 1000),   # Old square
        '2000x1000': (2000, 1000),   # Horizontal wide
        '1000x2000': (1000, 2000),   # Vertical tall
        '1920x960': (1920, 960),     # Horizontal for 4 images
        '960x1920': (960, 1920),     # Vertical for 4 images
        '1920x1920': (1920, 1920),   # Large square
        '1920x1280': (1920, 1280),   # Rectangle for 5 images
    }

    @staticmethod
    def parse_size(size_str: str) -> tuple:
        """
        Parse size string to (width, height) tuple.
        Supports both predefined sizes and custom WIDTHxHEIGHT format.

        Args:
            size_str: Size string like '1080x1080' or '800x600'

        Returns:
            tuple: (width, height) in pixels
        """
        # First check predefined sizes
        if size_str in AIImageService.SIZE_CONFIGS:
            return AIImageService.SIZE_CONFIGS[size_str]

        # Try to parse custom size format WIDTHxHEIGHT
        try:
            if 'x' in size_str.lower():
                parts = size_str.lower().split('x')
                width = int(parts[0].strip())
                height = int(parts[1].strip())

                # Validate reasonable dimensions (min 100, max 4096)
                if 100 <= width <= 4096 and 100 <= height <= 4096:
                    return (width, height)
                else:
                    print(f"Size {size_str} out of range (100-4096), using default")
                    return (1080, 1080)
        except (ValueError, IndexError) as e:
            print(f"Error parsing size {size_str}: {e}")

        # Fallback to default
        return (1080, 1080)

    @staticmethod
    def generate_image(
        prompt: str,
        user,
        size: str,
        creativity: str,
        reference_images: list = None,
        count: int = 3
    ) -> list:
        """
        Generate multiple images using Google Gemini AI

        Args:
            prompt: Text prompt describing the image to generate
            user: User instance
            size: Image size (required) - '1080x1080', '1200x628', '1080x1920', '1920x1080'
            creativity: Creativity level (required) - 'low', 'medium', 'high'
            reference_images: List of reference image file paths (optional)
            count: Number of images to generate (default: 3)

        Returns:
            list: List of generated image information dicts
        """
        import os
        import uuid
        import base64
        import io
        from pathlib import Path
        from PIL import Image
        from django.conf import settings
        from google import genai

        # Convert count to int (callers may pass float like 3.0)
        try:
            count = int(count) if count else 3
        except (ValueError, TypeError):
            count = 3

        # Get API key from settings
        api_key = config('GEMINI_API_KEY', default='')
        if not api_key:
            raise ValidationError("GEMINI_API_KEY is not configured")

        # Initialize Gemini client
        client = genai.Client(api_key=api_key)

        # Get model name from settings or use default
        model_name = config('GEMINI_IMAGE_MODEL', default='gemini-2.0-flash-preview-image-generation')

        # Map creativity level with detailed instructions
        creativity_instructions = {
            'low': """
- PHOTOREALISTIC 100% - ·∫¢nh ph·∫£i tr√¥ng nh∆∞ ch·ª•p t·ª´ m√°y ·∫£nh chuy√™n nghi·ªáp DSLR/mirrorless
- KH√îNG c√≥ ƒë·∫∑c ƒëi·ªÉm AI: kh√¥ng blur k·ª≥ l·∫°, kh√¥ng texture l·∫∑p l·∫°i, kh√¥ng finger/hand b·∫•t th∆∞·ªùng
- √Ånh s√°ng T·ª∞ NHI√äN nh∆∞ ch·ª•p th·∫≠t: soft lighting, golden hour, ho·∫∑c studio lighting th·ª±c t·∫ø
- M√†u s·∫Øc CH√ÇN TH·ª∞C: kh√¥ng qu√° saturate, kh√¥ng neon, kh√¥ng HDR qu√° m·ª©c
- Chi ti·∫øt TH·ª∞C T·∫æ: texture da, v·∫£i, kim lo·∫°i, g·ªó... ph·∫£i nh∆∞ th·∫≠t
- B·ªëi c·∫£nh TH·ª∞C T·∫æ: nh∆∞ location th·∫≠t ·ªü Vi·ªát Nam (vƒÉn ph√≤ng, c·ª≠a h√†ng, nh√† m√°y, showroom)
- S·∫£n ph·∫©m trong khung c·∫£nh T·ª∞ NHI√äN, kh√¥ng floating, kh√¥ng background gi·∫£ t·∫°o
- N·∫øu c√≥ ng∆∞·ªùi: t·ª∑ l·ªá c∆° th·ªÉ ƒë√∫ng, khu√¥n m·∫∑t t·ª± nhi√™n, bi·ªÉu c·∫£m th·∫≠t
- Focus v√† DOF (depth of field) nh∆∞ ·∫£nh ch·ª•p th·∫≠t""",
            'medium': """
- C√¢n b·∫±ng gi·ªØa ch√¢n th·∫≠t v√† th·∫©m m·ªπ cao c·∫•p
- C√≥ th·ªÉ t·ªëi ∆∞u m√†u s·∫Øc, √°nh s√°ng nh·∫π nh∆∞ng v·∫´n t·ª± nhi√™n
- V·∫´n gi·ªØ t√≠nh TH·ª∞C T·∫æ, kh√¥ng qu√° "·∫£o" ho·∫∑c gi·∫£ t·∫°o
- Ph√π h·ª£p ƒëƒÉng Facebook/Instagram Vi·ªát Nam
- Chi ti·∫øt ph·∫£i r√µ r√†ng, kh√¥ng b·ªã blur AI ƒëi·ªÉn h√¨nh
- Tr√°nh c√°c artifacts c·ªßa AI nh∆∞: b√†n tay 6 ng√≥n, ch·ªØ b·ªã m√©o, texture l·∫∑p l·∫°i""",
            'high': """
- S√°ng t·∫°o, ngh·ªá thu·∫≠t h∆°n nh∆∞ng V·∫™N PH·∫¢I TH·ª∞C T·∫æ
- C√≥ th·ªÉ th√™m hi·ªáu ·ª©ng √°nh s√°ng ƒë·∫πp, m√†u s·∫Øc ·∫•n t∆∞·ª£ng
- V·∫™N ph·∫£i h·ª£p l√Ω v√† tr√¥ng nh∆∞ ·∫£nh th·∫≠t ƒë∆∞·ª£c edit ƒë·∫πp
- Ph√π h·ª£p v·ªõi vƒÉn h√≥a Vi·ªát Nam
- Thu h√∫t m·∫°nh m·∫Ω tr√™n m·∫°ng x√£ h·ªôi
- Kh√¥ng ƒë∆∞·ª£c tr√¥ng fake ho·∫∑c AI-generated r√µ r√†ng"""
        }
        creativity_instruction = creativity_instructions.get(creativity, creativity_instructions['medium'])

        # Map size to Vietnamese description and context
        size_contexts = {
            '1080x1080': 'Vu√¥ng (1:1) - Ph√π h·ª£p Facebook feed, Instagram post',
            '1080x1350': 'D·ªçc (4:5) - T·ªëi ∆∞u mobile Facebook/Instagram',
            '1200x628': 'Banner ngang - Ph√π h·ª£p Facebook link preview, cover',
            '1080x1920': 'D·ªçc (9:16) - Ph√π h·ª£p Instagram/Facebook Story, Reels',
            '1920x1080': 'Ngang (16:9) - Ph√π h·ª£p YouTube thumbnail, website banner',
            # Facebook multi-image post sizes
            '1200x630': 'Banner ngang (1200x630) - Single Facebook post',
            '1000x1000': 'Vu√¥ng (1000x1000) - Facebook multi-image post',
            '2000x1000': 'Ngang r·ªông (2000x1000) - Facebook 2-3 ·∫£nh b·ªë c·ª•c ngang',
            '1000x2000': 'D·ªçc cao (1000x2000) - Facebook 2-3 ·∫£nh b·ªë c·ª•c d·ªçc',
            '1920x960': 'Ngang (1920x960) - Facebook 4 ·∫£nh - ·∫£nh header ngang',
            '960x1920': 'D·ªçc (960x1920) - Facebook 4 ·∫£nh - ·∫£nh header d·ªçc',
            '1920x1920': 'Vu√¥ng l·ªõn (1920x1920) - Facebook 4-5 ·∫£nh vu√¥ng',
            '1920x1280': 'Ch·ªØ nh·∫≠t (1920x1280) - Facebook 5 ·∫£nh ch·ªØ nh·∫≠t',
            'keep_original': 'Gi·ªØ nguy√™n k√≠ch th∆∞·ªõc ·∫£nh tham chi·∫øu',
        }
        size_context = size_contexts.get(size, f'K√≠ch th∆∞·ªõc {size}')

        # Build comprehensive Vietnamese system prompt
        system_prompt = f"""B·∫†N L√Ä CHUY√äN GIA THI·∫æT K·∫æ ·∫¢NH CHO M·∫†NG X√É H·ªòI VI·ªÜT NAM
Chuy√™n t·∫°o h√¨nh ·∫£nh ch·∫•t l∆∞·ª£ng cao cho Facebook, Instagram, TikTok t·∫°i th·ªã tr∆∞·ªùng Vi·ªát Nam.

=== NHI·ªÜM V·ª§: T·∫†O ·∫¢NH CH·∫§T L∆Ø·ª¢NG CHUY√äN NGHI·ªÜP ===

Y√äU C·∫¶U T·ª™ KH√ÅCH H√ÄNG:
{prompt}

=== TH√îNG S·ªê K·ª∏ THU·∫¨T ===
üìê K√≠ch th∆∞·ªõc: {size_context}
üé® M·ª©c ƒë·ªô s√°ng t·∫°o: {creativity.upper()}
{creativity_instruction}

=== NGUY√äN T·∫ÆC THI·∫æT K·∫æ ===

‚ö†Ô∏è QUAN TR·ªåNG NH·∫§T - PHOTOREALISTIC:
   - ·∫¢nh PH·∫¢I tr√¥ng nh∆∞ CH·ª§P TH·∫¨T t·ª´ m√°y ·∫£nh chuy√™n nghi·ªáp
   - KH√îNG ƒë∆∞·ª£c tr√¥ng nh∆∞ ·∫£nh AI t·∫°o ra
   - Chi ti·∫øt ph·∫£i TH·ª∞C T·∫æ 100%: texture, √°nh s√°ng, shadow, reflection
   - B·ªë c·ª•c nh∆∞ ·∫£nh ch·ª•p th·∫≠t, kh√¥ng gi·∫£ t·∫°o

1. PHONG C√ÅCH VI·ªÜT NAM:
   - Ph√π h·ª£p vƒÉn h√≥a, th·∫©m m·ªπ ng∆∞·ªùi Vi·ªát
   - B·ªëi c·∫£nh ph·∫£i nh∆∞ LOCATION TH·∫¨T ·ªü Vi·ªát Nam
   - N·ªôi dung ph√π h·ª£p v·ªõi ng∆∞·ªùi d√πng m·∫°ng x√£ h·ªôi VN
   - Tr√°nh c√°c y·∫øu t·ªë nh·∫°y c·∫£m vƒÉn h√≥a

2. T·ªêI ∆ØU CHO M·∫†NG X√É H·ªòI:
   - B·∫Øt m·∫Øt ngay l·∫≠p t·ª©c (scroll-stopping)
   - R√µ r√†ng, d·ªÖ nh√¨n tr√™n mobile
   - C√≥ ƒëi·ªÉm nh·∫•n (focal point) r√µ r√†ng
   - Ph√π h·ª£p thu·∫≠t to√°n Facebook/Instagram

3. CH·∫§T L∆Ø·ª¢NG H√åNH ·∫¢NH (NH∆Ø ·∫¢NH CH·ª§P TH·∫¨T):
   - ƒê·ªô ph√¢n gi·∫£i cao, s·∫Øc n√©t nh∆∞ ·∫£nh m√°y ·∫£nh
   - √Ånh s√°ng T·ª∞ NHI√äN: natural light, golden hour, studio soft light
   - M√†u s·∫Øc CH√ÇN TH·ª∞C, kh√¥ng over-saturated
   - Composition chuy√™n nghi·ªáp nh∆∞ nhi·∫øp ·∫£nh gia
   - Depth of field (DOF) v√† bokeh nh∆∞ ·∫£nh th·∫≠t
   - Shadow v√† highlight t·ª± nhi√™n

4. N·ªòI DUNG PH·∫¢I:
   - An to√†n, kh√¥ng vi ph·∫°m ch√≠nh s√°ch
   - T√≠ch c·ª±c, thu h√∫t t∆∞∆°ng t√°c
   - Ph√π h·ª£p m·ª•c ƒë√≠ch: b√°n h√†ng/marketing/branding
   - S·∫£n ph·∫©m/ng∆∞·ªùi trong KHUNG C·∫¢NH T·ª∞ NHI√äN

5. TUY·ªÜT ƒê·ªêI TR√ÅNH (ƒê·∫∑c ƒëi·ªÉm AI d·ªÖ nh·∫≠n ra):
   - H√¨nh ·∫£nh qu√° ·∫£o, kh√¥ng th·ª±c t·∫ø
   - Texture l·∫∑p l·∫°i ho·∫∑c blur k·ª≥ l·∫°
   - B√†n tay/ng√≥n tay b·∫•t th∆∞·ªùng
   - Ch·ªØ/text b·ªã m√©o ho·∫∑c v√¥ nghƒ©a
   - Background gi·∫£ t·∫°o, floating objects
   - √Ånh s√°ng/shadow kh√¥ng logic
   - Khu√¥n m·∫∑t "qu√° ho√†n h·∫£o" ho·∫∑c m√©o
   - Vi ph·∫°m b·∫£n quy·ªÅn (logo th∆∞∆°ng hi·ªáu n·ªïi ti·∫øng)
   - Qu√° nhi·ªÅu chi ti·∫øt g√¢y r·ªëi m·∫Øt

=== L∆ØU √ù ƒê·∫∂C BI·ªÜT ===
- ·∫¢nh ph·∫£i S·∫†CH, CHUY√äN NGHI·ªÜP, ƒêƒÇNG ƒê∆Ø·ª¢C NGAY
- Ph√π h·ª£p vƒÉn h√≥a v√† ph√°p lu·∫≠t Vi·ªát Nam
- T·ªëi ∆∞u cho mobile viewing (80% user xem tr√™n ƒëi·ªán tho·∫°i)
- C√≥ th·ªÉ d√πng l√†m thumbnail, preview, ho·∫∑c ·∫£nh ch√≠nh

‚õî‚õî‚õî QUY T·∫ÆC B·∫¢O V·ªÜ TH∆Ø∆†NG HI·ªÜU - B·∫ÆT BU·ªòC TU√ÇN TH·ª¶:
- TUY·ªÜT ƒê·ªêI KH√îNG t·∫°o h√¨nh ·∫£nh ti√™u c·ª±c, b·∫•t l·ª£i cho s·∫£n ph·∫©m/th∆∞∆°ng hi·ªáu
- KH√îNG t·∫°o ·∫£nh s·∫£n ph·∫©m b·ªã h·ªèng, b·∫©n, c≈© k·ªπ, k√©m ch·∫•t l∆∞·ª£ng
- KH√îNG t·∫°o b·ªëi c·∫£nh g√¢y c·∫£m gi√°c ti√™u c·ª±c (u √°m, b·∫©n th·ªâu, thi·∫øu chuy√™n nghi·ªáp)
- KH√îNG c√≥ y·∫øu t·ªë l√†m gi·∫£m ƒë·ªô tin t∆∞·ªüng c·ªßa kh√°ch h√†ng
- S·∫£n ph·∫©m ph·∫£i ƒë∆∞·ª£c th·ªÉ hi·ªán ƒê·∫∏P NH·∫§T, CH·∫§T L∆Ø·ª¢NG CAO NH·∫§T
- B·ªëi c·∫£nh ph·∫£i S·∫†CH S·∫º, CHUY√äN NGHI·ªÜP, t·∫°o ni·ªÅm tin
- H√¨nh ·∫£nh ph·∫£i T√îN VINH gi√° tr·ªã v√† ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m
- T·∫°o c·∫£m gi√°c CAO C·∫§P, ƒê√ÅNG TIN C·∫¨Y cho th∆∞∆°ng hi·ªáu

CH·ªà T·∫†O ·∫¢NH THEO Y√äU C·∫¶U, KH√îNG GI·∫¢I TH√çCH."""

        # Variation prompts ƒë·ªÉ t·∫°o ·∫£nh kh√°c nhau
        variation_instructions = [
            "T·∫°o phi√™n b·∫£n v·ªõi G√ìC NH√åN/G√ìC CH·ª§P kh√°c bi·ªát, composition ƒë·ªôc ƒë√°o.",
            "T·∫°o phi√™n b·∫£n v·ªõi B·ªê C·ª§C v√† LIGHTING kh√°c, t·∫°o c·∫£m gi√°c m·ªõi m·∫ª.",
            "T·∫°o phi√™n b·∫£n v·ªõi STYLE v√† CHI TI·∫æT PH·ª§ kh√°c, nh∆∞ng gi·ªØ ch·ªß ƒë·ªÅ ch√≠nh.",
            "T·∫°o phi√™n b·∫£n S√ÅNG T·∫†O v·ªõi m√†u s·∫Øc v√† hi·ªáu ·ª©ng kh√°c bi·ªát.",
            "T·∫°o phi√™n b·∫£n MINIMALIST ho·∫∑c c√≥ ƒëi·ªÉm nh·∫•n kh√°c."
        ]

        generated_images = []

        # Handle 'keep_original' - detect size from reference image
        if size == 'keep_original' and reference_images:
            try:
                ref_img = Image.open(reference_images[0])
                target_size = ref_img.size
                ref_img.close()
                print(f"[AI Image] Using reference image size: {target_size}")
            except Exception as e:
                print(f"[AI Image] Could not detect reference size: {e}, using default 1080x1080")
                target_size = (1080, 1080)
        else:
            # Parse size - supports both predefined and custom WIDTHxHEIGHT format
            target_size = AIImageService.parse_size(size)

        user_dir = Path(settings.MEDIA_ROOT) / 'uploads' / str(user.id)
        user_dir.mkdir(parents=True, exist_ok=True)

        # Token tracking for image generation
        total_prompt_tokens = 0
        total_output_tokens = 0
        total_tokens = 0

        for variation_idx in range(count):
            try:
                # Add variation instruction to prompt
                variation_text = variation_instructions[variation_idx % len(variation_instructions)]
                varied_prompt = f"""{system_prompt}

=== VARIATION {variation_idx + 1}/{count} ===
{variation_text}
ƒê·∫£m b·∫£o ·∫£nh n√†y KH√ÅC BI·ªÜT v·ªõi c√°c phi√™n b·∫£n kh√°c nh∆∞ng v·∫´n PH√ô H·ª¢P v·ªõi y√™u c·∫ßu g·ªëc."""

                # Build content list
                contents = [varied_prompt]

                # Add reference images if provided
                if reference_images:
                    for img_path in reference_images:
                        try:
                            img = Image.open(img_path)
                            contents.append(img)
                        except Exception as e:
                            print(f"Error loading reference image {img_path}: {e}")

                # Generate image using Gemini
                response = client.models.generate_content(
                    model=model_name,
                    contents=contents,
                    config=genai.types.GenerateContentConfig(
                        response_modalities=['Text', 'Image']
                    )
                )

                # Track token usage from this call
                if hasattr(response, 'usage_metadata') and response.usage_metadata:
                    usage = response.usage_metadata
                    if hasattr(usage, 'prompt_token_count'):
                        total_prompt_tokens += usage.prompt_token_count or 0
                    if hasattr(usage, 'candidates_token_count'):
                        total_output_tokens += usage.candidates_token_count or 0
                    if hasattr(usage, 'total_token_count'):
                        total_tokens += usage.total_token_count or 0

                # Check if response has candidates
                if not response.candidates:
                    print(f"Variation {variation_idx + 1}: No candidates in response")
                    continue

                candidate = response.candidates[0]

                # Check if candidate was blocked
                if hasattr(candidate, 'finish_reason') and candidate.finish_reason:
                    finish_reason = str(candidate.finish_reason)
                    if 'SAFETY' in finish_reason or 'BLOCK' in finish_reason:
                        print(f"Variation {variation_idx + 1}: Blocked - {finish_reason}")
                        continue

                # Check if content exists
                if not candidate.content or not candidate.content.parts:
                    print(f"Variation {variation_idx + 1}: No content parts")
                    continue

                # Extract ALL images from response parts (kh√¥ng break)
                for part in candidate.content.parts:
                    if part.inline_data is not None:
                        # Decode base64 image data
                        image_data = base64.b64decode(part.inline_data.data)
                        generated_image = Image.open(io.BytesIO(image_data))

                        # Log original AI-generated size for debugging
                        original_ai_size = generated_image.size
                        print(f"[AI Image] Original from Gemini: {original_ai_size}, Target: {target_size}")

                        # Resize to requested size if different
                        needs_upscale = (target_size[0] > original_ai_size[0] or
                                        target_size[1] > original_ai_size[1])

                        if generated_image.size != target_size:
                            generated_image = generated_image.resize(target_size, Image.Resampling.LANCZOS)

                        # Apply sharpening to improve clarity (especially after upscale)
                        from PIL import ImageFilter, ImageEnhance

                        if needs_upscale:
                            # Stronger sharpening for upscaled images
                            generated_image = generated_image.filter(
                                ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3)
                            )
                        else:
                            # Light sharpening for same size or downscaled
                            generated_image = generated_image.filter(
                                ImageFilter.UnsharpMask(radius=1, percent=80, threshold=2)
                            )

                        # Slight contrast boost for more punch
                        enhancer = ImageEnhance.Contrast(generated_image)
                        generated_image = enhancer.enhance(1.05)

                        # Convert RGBA to RGB if necessary
                        if generated_image.mode == 'RGBA':
                            rgb_img = Image.new('RGB', generated_image.size, (255, 255, 255))
                            rgb_img.paste(generated_image, mask=generated_image.split()[3])
                            generated_image = rgb_img

                        # Save as high-quality PNG (lossless, larger file ~3-8MB for high-res images)
                        # PNG compress_level=0 = no compression = maximum quality & larger file
                        filename = f"ai_{uuid.uuid4()}.png"
                        file_path = user_dir / filename
                        generated_image.save(str(file_path), 'PNG', compress_level=0)

                        # Get file size
                        file_size = os.path.getsize(file_path)

                        generated_images.append({
                            'file_url': f"/media/uploads/{user.id}/{filename}",
                            'file_path': str(file_path),
                            'file_size': file_size,
                            'width': target_size[0],
                            'height': target_size[1],
                            'filename': filename,
                            'variation': variation_idx + 1
                        })

            except Exception as e:
                print(f"Error generating variation {variation_idx + 1}: {str(e)}")
                continue

        if not generated_images:
            raise ValidationError("AI kh√¥ng th·ªÉ t·∫°o ·∫£nh n√†o. Vui l√≤ng th·ª≠ l·∫°i v·ªõi prompt kh√°c.")

        # Return images with token usage info
        return {
            'images': generated_images,
            'token_usage': {
                'prompt_tokens': total_prompt_tokens,
                'output_tokens': total_output_tokens,
                'total_tokens': total_tokens
            },
            'model': model_name
        }

    @staticmethod
    def save_reference_image(file, user) -> str:
        """
        Save reference image temporarily for AI generation

        Args:
            file: Uploaded file
            user: User instance

        Returns:
            str: Path to saved reference image
        """
        import os
        import uuid
        from pathlib import Path
        from django.conf import settings

        # Create temp directory for reference images
        temp_dir = Path(settings.MEDIA_ROOT) / 'temp' / str(user.id)
        temp_dir.mkdir(parents=True, exist_ok=True)

        # Save file
        filename = f"ref_{uuid.uuid4()}{Path(file.name).suffix}"
        file_path = temp_dir / filename

        with open(file_path, 'wb+') as destination:
            for chunk in file.chunks():
                destination.write(chunk)

        return str(file_path)

    @staticmethod
    def cleanup_reference_images(file_paths: list):
        """
        Clean up temporary reference images after generation

        Args:
            file_paths: List of file paths to delete
        """
        import os

        for path in file_paths:
            try:
                if os.path.exists(path):
                    os.remove(path)
            except Exception as e:
                print(f"Error deleting reference image {path}: {e}")
